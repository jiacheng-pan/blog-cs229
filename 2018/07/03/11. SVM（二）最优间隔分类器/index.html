<!DOCTYPE html>
<html lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>11. SVM（二）最优间隔分类器 | Machine Learning | cs229</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="最优间隔分类器（Optimal Margin Classifier）。其目标是使得最小几何间隔最大化（10. SVM（一）概念）：$$\text{目标(1):} \\\max_{w, b} \gamma \\\text{ s.t. } y^{(i)} \cdot ((\frac{w}{||w||})^T \cdot x^{(i)}+\frac{b}{||w||}) \geq \gamma, i=1">
<meta name="keywords" content="SVM,最优间隔分类器,拉格朗日乘子法">
<meta property="og:type" content="article">
<meta property="og:title" content="11. SVM（二）最优间隔分类器">
<meta property="og:url" content="http://jackieanxis.github.io/2018/07/03/11. SVM（二）最优间隔分类器/index.html">
<meta property="og:site_name" content="Machine Learning | cs229">
<meta property="og:description" content="最优间隔分类器（Optimal Margin Classifier）。其目标是使得最小几何间隔最大化（10. SVM（一）概念）：$$\text{目标(1):} \\\max_{w, b} \gamma \\\text{ s.t. } y^{(i)} \cdot ((\frac{w}{||w||})^T \cdot x^{(i)}+\frac{b}{||w||}) \geq \gamma, i=1">
<meta property="og:locale" content="Chinese">
<meta property="og:image" content="http://o6vut8vrh.bkt.clouddn.com/18-7-4/9336603.jpg">
<meta property="og:updated_time" content="2018-07-22T13:27:45.445Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="11. SVM（二）最优间隔分类器">
<meta name="twitter:description" content="最优间隔分类器（Optimal Margin Classifier）。其目标是使得最小几何间隔最大化（10. SVM（一）概念）：$$\text{目标(1):} \\\max_{w, b} \gamma \\\text{ s.t. } y^{(i)} \cdot ((\frac{w}{||w||})^T \cdot x^{(i)}+\frac{b}{||w||}) \geq \gamma, i=1">
<meta name="twitter:image" content="http://o6vut8vrh.bkt.clouddn.com/18-7-4/9336603.jpg">
  
  
    <link rel="icon" href="http://o6vut8vrh.bkt.clouddn.com/avatar.png">
  
  <link rel="stylesheet" href="/blog-cs229/css/typing.css">
  <link rel="stylesheet" href="/blog-cs229/css/donate.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  
</head>

  
    
      <body>
    
  
      <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container" class="container">
        <article id="post-11. SVM（二）最优间隔分类器" class="article article-type-post" itemscope itemprop="blogPost">
  <header id="header" class="header">
    <div class="mobile-nav">
      <h1 class="nickname">Jackie Anxis</h1>
      <a id="menu">
        &#9776; Menu
      </a>
    </div>
    
        <nav id="main-nav" class="main-nav nav-left">
    
    
      <a class="main-nav-link" href="http://jackieanxis.github.io">Home</a>
    
      <a class="main-nav-link" href="http://jackieanxis.github.io/blog-frontend">FrontEnd</a>
    
      <a class="main-nav-link" href="http://jackieanxis.github.io/blog-cs229">MLcs229</a>
    
      <a class="main-nav-link" href="http://jackieanxis.github.io/blog-papers">PaperReading</a>
    
      <a class="main-nav-link" href="https://github.com/JackieAnxis">Github</a>
    
      <a class="main-nav-link" href="http://jackieanxis.github.io/blog-others">Others</a>
    
      <a class="main-nav-link" href="/blog-cs229/about">About</a>
    
  </nav>
</header>

  <hr/>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      11. SVM（二）最优间隔分类器
    </h1>
  

      </header>
    
    <div class="article-entry typo" itemprop="articleBody">
      
        <p><strong>最优间隔分类器</strong>（<em>Optimal Margin Classifier</em>）。其目标是使得最小几何间隔最大化（<a href="https://jackieanxis.github.io/blog-cs229/2018/07/02/10.%20SVM%EF%BC%88%E4%B8%80%EF%BC%89%E6%A6%82%E5%BF%B5/">10. SVM（一）概念</a>）：<br>$$<br>\text{目标(1):} \\<br>\max_{w, b} \gamma \\<br>\text{ s.t. } y^{(i)} \cdot ((\frac{w}{||w||})^T \cdot x^{(i)}+\frac{b}{||w||}) \geq \gamma, i=1,\ldots,n<br>$$<br>我们知道，$\hat{\gamma} = \frac{\gamma}{||w||}$，所以上面的目标可以等同于：<br>$$<br>\text{目标(2):} \\<br>\max_{w, b} \frac{\hat{\gamma}}{||w||} \\<br>\text{ s.t. }y^{(i)} \cdot (w^T \cdot x^{(i)}+b) \geq \hat{\gamma}, i=1,\ldots,n<br>$$<br>为了最大化上述值，我们有两种策略。</p>
<ol>
<li>增大$\hat{\gamma}$</li>
<li>减小$||w||$</li>
</ol>
<p>针对第一种可能，我们要证明其无效性。假如，我们增大$\hat{\gamma}$到$\hat{\gamma}_1 := \lambda \hat{\gamma}$，因为$\hat{\gamma}=y(w^Tx+b)$，可以视作$w_1:=\lambda w, b_1 = \lambda b$。所以，此时<br>$$<br>\frac{\hat{\gamma_1}}{||w_1||}=\frac{\lambda \hat{\gamma}}{||\lambda w||} = \frac{\hat{\gamma}}{||w||} \\<br>$$<br>没有发生任何改变，所以第一条策略不可行。于是，我们可以固定$\hat{\gamma}=1$</p>
<p>此时，上述目标(2)可以表述成：<br>$$<br>\text{目标(3):} \\<br>\min_{w, b} \frac{1}{2}||w|^2 \\<br>\text{ s.t. }y^{(i)} \cdot (w^T \cdot x^{(i)}+b) \geq 1, i=1,\ldots,n<br>$$</p>
<h2 id="拉格朗日乘子法（Lagrange-Multiplier）"><a href="#拉格朗日乘子法（Lagrange-Multiplier）" class="headerlink" title="拉格朗日乘子法（Lagrange Multiplier）"></a>拉格朗日乘子法（Lagrange Multiplier）</h2><p>为了解决上述的<strong>凸优化问题</strong>，我们引入拉格朗日乘子法<em>Lagrange Multiplier</em>来解决这个问题。</p>
<p>我们首先来看看<strong>凸优化问题</strong>的定义：<br>$$<br>\min_wf(w) \\<br>\text{s.t. }g_i(w) \leq 0, h_i(w) =0<br>$$<br>构建拉格朗日乘子：<br>$$<br>{\cal L}(w, \alpha, \beta) = f(w)+\sum_i\alpha_ig_i(w)+\sum_i\beta_ih_i(w)<br>$$<br>定义：<br>$$<br>\theta_p(w) = \max_{\alpha_i&gt;0, \beta}{\cal L}(w, \alpha, \beta)<br>$$<br>观察$\theta_p(w)$：</p>
<ol>
<li>如果$g_i(w)&gt;0$，那么$\theta_p(w)=+\infty$（因为$\alpha$可以取任意大值）。</li>
<li>如果$h_i(w) \neq 0$，那么$\theta_p(w)=+\infty$（因为$\beta$可以取$+\infty/-\infty$）。</li>
</ol>
<p>所以，在满足约束的情况下，$\theta_p(w)=f(w)$，$\min_w \theta_p(w)=\min_w f(w)$，因为使得${\cal L}(w, \alpha, \beta)$最大的方法，就是其他所有项全是0。那么，可以得出这样的结论：<br>$$<br>\theta_p(w)=\begin{cases}<br>f(w), &amp;\text{满足约束} \\<br>\infty, &amp;\text{不满足约束}<br>\end{cases}<br>$$<br>因此，在满足条件的情况下，$\min_w\theta_p(w)$等价于$min_wf(w)$。</p>
<p>我们将最优间隔分类器的目标重新表示一下：<br>$$<br>p^\ast =\min_{w, b}\max_\alpha {\cal L(w, \alpha, b)} \\<br>{\cal L}(w, \alpha, b) = \frac{1}{2}||w||^2+\sum_i\alpha_i(1-y^{(i)}(w^T x^{(i)}+b))<br>$$<br>其中，直接忽略了$h_i(w)=0$的约束，而$g_i(w,b)=1-y^{(i)}(w^Tx^{(i)}+b) \leq 0, f(w)=\frac{1}{2}||w||^2$</p>
<h2 id="对偶问题（Dual-Problem）"><a href="#对偶问题（Dual-Problem）" class="headerlink" title="对偶问题（Dual Problem）"></a>对偶问题（Dual Problem）</h2><p>一般来说，将原始问题转化成对偶问题来求解。一是因为对偶问题往往比较容易求解，二是因为对偶问题引入了核函数，方便推广到非线性分类的情况。</p>
<p>我们看到，之前的原始问题，是<br>$$<br>p^\ast =\min_{w, b}\max_\alpha {\cal L}(w, \alpha, b)<br>$$</p>
<p>那么，定义其对偶问题：</p>
<p>$$<br>l^\ast =\max_\alpha\min_{w,b}{\cal L}(w, \alpha, b)<br>$$</p>
<p>接下去，我们求解对偶问题：</p>
<p>先求解$\min_{w,b}{\cal L}(w, \alpha, b)$：</p>
<p>分别求偏导，使其等于0，导出最小值：<br>$$<br>\begin{align}<br>&amp; \nabla_w{\cal L}(w, \alpha, b) =w-\sum_{i=1}\alpha_iy^{(i)}x^{(i)}=0 \\<br>&amp; \nabla_b{\cal L}(w, \alpha, b) =\sum_{i=1}\alpha_iy^{(i)}=0<br>\end{align}<br>$$</p>
<p>得到：</p>
<p>$$<br>w =\sum_{i=1}\alpha_iy^{(i)}x^{(i)} \\<br>\sum_{i=1}\alpha_iy^{(i)} = 0<br>$$</p>
<p>代入${\cal L}(w, \alpha, b)$，就可以得到最小值：</p>
<p>$$<br>\begin{align}<br>{\cal L}(w, \alpha, b) &amp;= \frac{1}{2}||w||^2+\sum_i\alpha_i(1-y^{(i)}(w^T x^{(i)}+b)) \\<br>\min_{w, b}{\cal L}(w, \alpha, b) &amp;=\underbrace{\sum_{i=1}\alpha_i-\frac{1}{2}\sum_{i=1}\sum_{j=1}\alpha_i\alpha_jy_iy_j(x_i \cdot x_j)}_{W(\alpha)}<br>\end{align}<br>$$</p>
<p>于是，我们的对偶问题简化到了对$W(\alpha)$最大化：<br>$$<br>\max_\alpha W(\alpha) \\<br>\text{s.t. }\alpha_i \geq 0, \sum_iy_i\alpha_i=0<br>$$</p>
<p>假设，我们解得的对偶问题的解为：$\alpha^\ast =[\alpha_1^\ast ,\alpha_2^\ast , \ldots, \alpha_m^\ast ]$，那么最终原始问题的解可以表示成：</p>
<p>$$<br>w^\ast =\sum_{i=1}\alpha_i^\ast y^{(i)}x^{(i)}<br>$$</p>
<p>在原始问题中，还有$b$未得到解决。我们先来观察一下约束项：<br>$$<br>g_i(w,b)=1-y{(i)}(w^Tx^{(i)}+b) \leq 0<br>$$<br><img src="http://o6vut8vrh.bkt.clouddn.com/18-7-4/9336603.jpg" alt=""></p>
<p>我们知道，在数据中，只有少数的几个数据点，他们的函数距离为1（最小），也即$g_i(w,b)=0$，如图所示。</p>
<p>在整个数据集中，只有这些数据点对约束超平面起了作用，这些数据点被称为支持向量（<em>support vector</em>），其对应的$\alpha_i^\ast  \neq 0$，而其他不是支持向量的数据点，没有对约束超平面起作用，其$\alpha_i^\ast =0$。</p>
<p>此时，我们已经得到了$w^\ast $，而$b^\ast $的计算如下，找到一个数据点，其$\alpha_j^\ast  \neq 0$(也就是支持向量，其函数间隔为1)，我们就能得到：</p>
<p>$$<br>y^{(j)}(w^{*T}x^{(j)}+b^\ast )=1<br>\Rightarrow<br>b^\ast =y^{(j)}-\sum_{i=1}\alpha_i^\ast y^{(i)}(x^{(i)} \cdot x^{(j)})<br>$$</p>

      
    </div>
    <footer class="article-footer">
      <ul class="article-meta">
        <li>
          <span class="label">Published Date:</span>
          <a href="/blog-cs229/2018/07/03/11. SVM（二）最优间隔分类器/" class="article-date">
  <time datetime="2018-07-03T08:27:00.000Z" itemprop="datePublished">2018-07-03</time>
</a>

        </li>
        
          <li>
            <span class="label">Category:</span>
            
  <div class="article-category">
    <a class="article-category-link" href="/blog-cs229/categories/SVM/">SVM</a>
  </div>


          </li>
        
        
          <li>
            <span class="label">Tag:</span>
            
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog-cs229/tags/SVM/">SVM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog-cs229/tags/拉格朗日乘子法/">拉格朗日乘子法</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog-cs229/tags/最优间隔分类器/">最优间隔分类器</a></li></ul>


          </li>
        
        <hr/>
      </ul>
    </footer>
  </div>
  
    
<nav id="article-nav" class="article-nav">
  
    <a href="/blog-cs229/2018/07/22/12. SVM（三）核函数/" id="article-nav-newer" class="article-nav-link-wrap newer">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          12. SVM（三）核函数
        
      </div>
    </a>
  
  
    <a href="/blog-cs229/2018/07/02/10. SVM（一）概念/" id="article-nav-older" class="article-nav-link-wrap older">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">10. SVM（一）概念</div>
    </a>
  
</nav>


  
</article>








      </div>
      
    <footer id="footer" class="post-footer footer">
      
      <hr/>
      <div id="footerContent" class="footer-content">
        <p>nothing</p>


      </div>
    </footer>

      





<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.10/clipboard.min.js"></script>


  <link rel="stylesheet" href="/blog-cs229/fancybox/jquery.fancybox.css">
  <script src="/blog-cs229/fancybox/jquery.fancybox.pack.js"></script>


<script src="/blog-cs229/js/typing.js"></script>
<!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->







    </div>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>
